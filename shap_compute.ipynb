{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import shap\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import xgboost as xgb\r\n",
    "\r\n",
    "import numpy as np"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "def read_xgboost_data(iter):\r\n",
    "    \"\"\"\r\n",
    "    This function reads training and test data for computing SHAP value\r\n",
    "    \"\"\"\r\n",
    "    dtrain = xgb.DMatrix(f\"./data/WS/model_fits/iter={iter}opt=1dtrain.data\")\r\n",
    "    dtest =xgb.DMatrix(f\"./data/WS/model_fits/iter={iter}opt=1dtest.data\")\r\n",
    "\r\n",
    "    return dtrain, dtest"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "def read_xgboost_model(iter):\r\n",
    "    \"\"\"\r\n",
    "    This function reads trained xgboost models;\r\n",
    "    The solution from the following link is used:\r\n",
    "    https://github.com/slundberg/shap/issues/1215#issue-619973736\r\n",
    "    https://github.com/slundberg/shap/issues/1215#issuecomment-641102855\r\n",
    "    \"\"\"\r\n",
    "    model_fname = (f\"./data/WS/model_fits/gof_iter={iter}opt=1.model\" )\r\n",
    "\r\n",
    "    booster = xgb.Booster()\r\n",
    "    booster.load_model(model_fname)\r\n",
    "\r\n",
    "    model_bytearray = booster.save_raw()[4:]\r\n",
    "    booster.save_raw = lambda: model_bytearray\r\n",
    "\r\n",
    "    return booster"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "n_train = [29061, 31229, 31064, 32135, 31851]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "for iter in range(5):\r\n",
    "    iter = iter + 1\r\n",
    "    all_data = np.genfromtxt(f\"./data/WS/model_fits/iter={iter}opt=1_train_test.csv\", delimiter=\",\", skip_header=1)\r\n",
    "    all_data = all_data[:,1:]\r\n",
    "    booster = read_xgboost_model(iter)\r\n",
    "\r\n",
    "    backgroud_data = all_data[0:n_train[iter - 1],:]\r\n",
    "\r\n",
    "    explainer = shap.TreeExplainer(\r\n",
    "        booster, feature_perturbation=\"interventional\", data=backgroud_data\r\n",
    "    )\r\n",
    "\r\n",
    "    test_shap_values = explainer.shap_values(all_data)\r\n",
    "    np.savetxt(f\"./data/WS/model_fits/int_SHAP_test_iter{iter}.csv\", test_shap_values, delimiter=\",\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 72%|==============      | 27926/38835 [03:05<01:12]       "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "explainer = shap.TreeExplainer(\r\n",
    "    booster, feature_perturbation=\"interventional\", data=backgroud_data\r\n",
    ")\r\n",
    "\r\n",
    "test_shap_values = explainer.shap_values(backgroud_data)\r\n",
    "np.savetxt(f\"./data/WS/model_fits/int_SHAP_test_iter{iter}.csv\", test_shap_values, delimiter=\",\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|===================| 38648/38835 [00:52<00:00]       "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "%%time\r\n",
    "# Compute shap values using GPU with xgboost\r\n",
    "# model.set_param({\"predictor\":\"cpu_predictor\"})\r\n",
    "model.set_param({\"predictor\": \"gpu_predictor\"})\r\n",
    "shap_values = model.predict(dtrain, pred_contribs=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Wall time: 2.7 s\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "shap_interaction_values = model.predict(dtrain, pred_interactions=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "source": [
    "import shap\r\n",
    "\r\n",
    "\r\n",
    "# shap will call the GPU accelerated version as long as the predictor parameter is set to \"gpu_predictor\"\r\n",
    "model.set_param({\"predictor\": \"gpu_predictor\"})\r\n",
    "backgroud_data = X\r\n",
    "explainer = shap.TreeExplainer(model, feature_perturbation=\"interventional\", data=backgroud_data)\r\n",
    "%time shap_values = explainer.shap_values(X, )\r\n",
    "\r\n",
    "# visualize the first prediction's explanation\r\n",
    "shap.force_plot(\r\n",
    "    explainer.expected_value,\r\n",
    "    shap_values[0, :],\r\n",
    "    X[0, :],\r\n",
    "    feature_names=data.feature_names,\r\n",
    "    matplotlib=True\r\n",
    ")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      " 59%|============        | 12202/20640 [11:20<07:50]       "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import xgboost as xgb\r\n",
    "from sklearn.datasets import fetch_covtype\r\n",
    "from sklearn.model_selection import train_test_split\r\n",
    "import time\r\n",
    "\r\n",
    "# Fetch dataset using sklearn\r\n",
    "cov = fetch_covtype()\r\n",
    "X = cov.data\r\n",
    "y = cov.target\r\n",
    "\r\n",
    "# Create 0.75/0.25 train/test split\r\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, train_size=0.75,\r\n",
    "                                                    random_state=42)\r\n",
    "\r\n",
    "# Specify sufficient boosting iterations to reach a minimum\r\n",
    "num_round = 3000\r\n",
    "\r\n",
    "# Leave most parameters as default\r\n",
    "param = {'objective': 'multi:softmax', # Specify multiclass classification\r\n",
    "         'num_class': 8, # Number of possible output classes\r\n",
    "         'tree_method': 'gpu_hist' # Use GPU accelerated algorithm\r\n",
    "         }\r\n",
    "\r\n",
    "# Convert input data from numpy to XGBoost format\r\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\r\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\r\n",
    "\r\n",
    "gpu_res = {} # Store accuracy result\r\n",
    "tmp = time.time()\r\n",
    "# Train model\r\n",
    "xgb.train(param, dtrain, num_round, evals=[(dtest, 'test')], evals_result=gpu_res)\r\n",
    "print(\"GPU Training Time: %s seconds\" % (str(time.time() - tmp)))\r\n",
    "\r\n",
    "# Repeat for CPU algorithm\r\n",
    "tmp = time.time()\r\n",
    "param['tree_method'] = 'hist'\r\n",
    "cpu_res = {}\r\n",
    "xgb.train(param, dtrain, num_round, evals=[(dtest, 'test')], evals_result=cpu_res)\r\n",
    "print(\"CPU Training Time: %s seconds\" % (str(time.time() - tmp)))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "model = xgb.Booster()\r\n",
    "model.load_model(\"data/WS/model_fits/xgb_opt_1_iter_1/model_3.model\")"
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "XGBoostError",
     "evalue": "[16:11:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/dmlc-core/src/io/local_filesys.cc:209: Check failed: allow_null:  LocalFileSystem::Open \"data/WS/model_fits/xgb_opt_1_iter_1/model_3.model\": No such file or directory",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mXGBoostError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_25920/2951890355.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxgb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBooster\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/WS/model_fits/xgb_opt_1_iter_1/model_3.model\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\xgboost-env\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36mload_model\u001b[1;34m(self, fname)\u001b[0m\n\u001b[0;32m   1980\u001b[0m             \u001b[1;31m# from URL.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1981\u001b[0m             \u001b[0mfname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfspath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexpanduser\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1982\u001b[1;33m             _check_call(_LIB.XGBoosterLoadModel(\n\u001b[0m\u001b[0;32m   1983\u001b[0m                 self.handle, c_str(fname)))\n\u001b[0;32m   1984\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\xgboost-env\\lib\\site-packages\\xgboost\\core.py\u001b[0m in \u001b[0;36m_check_call\u001b[1;34m(ret)\u001b[0m\n\u001b[0;32m    208\u001b[0m     \"\"\"\n\u001b[0;32m    209\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 210\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mXGBoostError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpy_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_LIB\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXGBGetLastError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    211\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mXGBoostError\u001b[0m: [16:11:22] C:/Users/Administrator/workspace/xgboost-win64_release_1.4.0/dmlc-core/src/io/local_filesys.cc:209: Check failed: allow_null:  LocalFileSystem::Open \"data/WS/model_fits/xgb_opt_1_iter_1/model_3.model\": No such file or directory"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "booster = xgb.Booster()\r\n",
    "booster.load_model(\"C:/Users/User/Documents/ExplainableML_SuDS/data/WS/model_fits/xgb_opt_1_iter_1/model_1.model\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "   explainer = shap.TreeExplainer(\r\n",
    "        booster, feature_perturbation=\"observational\"\r\n",
    "    )"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "import shap\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import xgboost as xgb\r\n",
    "\r\n",
    "import numpy as np\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "source": [
    "eval_grid = np.genfromtxt(\r\n",
    "    \"C:/Users/User/Documents/ExplainableML_SuDS/data/WS/model_fits/optimal_candidate_id.csv\",\r\n",
    "    delimiter=\",\",\r\n",
    "    skip_header=1,\r\n",
    "    dtype=\"int\",\r\n",
    ")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "eval_grid"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[  1,   1,  97],\n",
       "       [  1,   2,  93],\n",
       "       [  1,   3,  73],\n",
       "       [  1,   4,  89],\n",
       "       [  1,   5,  89],\n",
       "       [  2,   1,  64],\n",
       "       [  2,   2, 100],\n",
       "       [  2,   3, 100],\n",
       "       [  2,   4,  94],\n",
       "       [  2,   5,  87],\n",
       "       [  3,   1,  76],\n",
       "       [  3,   2,  77],\n",
       "       [  3,   3,  88],\n",
       "       [  3,   4,  92],\n",
       "       [  3,   5,  99],\n",
       "       [  4,   1,  77],\n",
       "       [  4,   2,  70],\n",
       "       [  4,   3,  83],\n",
       "       [  4,   4,  70],\n",
       "       [  4,   5,  73]])"
      ]
     },
     "metadata": {},
     "execution_count": 20
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "import shap\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import xgboost as xgb\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "\r\n",
    "def read_xgboost_data(option, outer_i, model_id):\r\n",
    "    \"\"\"\r\n",
    "    This function reads training and test data for computing SHAP value\r\n",
    "    \"\"\"\r\n",
    "    train_fname = (\r\n",
    "        \"./data/WS/model_fits/xgb_opt_\"\r\n",
    "        + option.__str__()\r\n",
    "        + \"_iter_\"\r\n",
    "        + outer_i.__str__()\r\n",
    "        + \"/train_\"\r\n",
    "        + model_id.__str__()\r\n",
    "        + \".csv\"\r\n",
    "    )\r\n",
    "\r\n",
    "    test_fname = (\r\n",
    "        \"./data/WS/model_fits/xgb_opt_\"\r\n",
    "        + option.__str__()\r\n",
    "        + \"_iter_\"\r\n",
    "        + outer_i.__str__()\r\n",
    "        + \"/test_\"\r\n",
    "        + model_id.__str__()\r\n",
    "        + \".csv\"\r\n",
    "    )\r\n",
    "    dtrain = np.genfromtxt(train_fname, delimiter=\",\", skip_header=1)\r\n",
    "    dtest = np.genfromtxt(test_fname, delimiter=\",\", skip_header=1)\r\n",
    "\r\n",
    "    return dtrain, dtest\r\n",
    "\r\n",
    "\r\n",
    "def read_xgboost_model(option, outer_i, model_id):\r\n",
    "    \"\"\"\r\n",
    "    This function reads trained xgboost models;\r\n",
    "    The solution from the following link is used:\r\n",
    "    https://github.com/slundberg/shap/issues/1215#issue-619973736\r\n",
    "    https://github.com/slundberg/shap/issues/1215#issuecomment-641102855\r\n",
    "    \"\"\"\r\n",
    "    model_fname = (\r\n",
    "        \"./data/WS/model_fits/xgb_opt_\"\r\n",
    "        + option.__str__()\r\n",
    "        + \"_iter_\"\r\n",
    "        + outer_i.__str__()\r\n",
    "        + \"/model_\"\r\n",
    "        + model_id.__str__()\r\n",
    "        + \".model\"\r\n",
    "    )\r\n",
    "\r\n",
    "    booster = xgb.Booster()\r\n",
    "    booster.load_model(model_fname)\r\n",
    "\r\n",
    "    model_bytearray = booster.save_raw()[4:]\r\n",
    "    booster.save_raw = lambda: model_bytearray\r\n",
    "\r\n",
    "    return booster\r\n",
    "\r\n",
    "\r\n",
    "def save_shap(option, outer_i, model_id, backgroud_portion):\r\n",
    "    \"\"\"\r\n",
    "    This function computes SHAP value and save it\r\n",
    "    \"\"\"\r\n",
    "\r\n",
    "    shap_train_fname = (\r\n",
    "        \"./data/WS/model_fits/xgb_opt_\"\r\n",
    "        + option.__str__()\r\n",
    "        + \"_iter_\"\r\n",
    "        + outer_i.__str__()\r\n",
    "        + \"/shap_train_\"\r\n",
    "        + model_id.__str__()\r\n",
    "        + \".csv\"\r\n",
    "    )\r\n",
    "\r\n",
    "    shap_test_fname = (\r\n",
    "        \"./data/WS/model_fits/xgb_opt_\"\r\n",
    "        + option.__str__()\r\n",
    "        + \"_iter_\"\r\n",
    "        + outer_i.__str__()\r\n",
    "        + \"/shap_test_\"\r\n",
    "        + model_id.__str__()\r\n",
    "        + \".csv\"\r\n",
    "    )\r\n",
    "\r\n",
    "    # read dataset\r\n",
    "    dtrain, dtest = read_xgboost_data(option, outer_i, model_id)\r\n",
    "\r\n",
    "    # read model\r\n",
    "    booster = read_xgboost_model(option, outer_i, model_id)\r\n",
    "\r\n",
    "    # set up TreeExplainer\r\n",
    "    np.random.seed(option * outer_i * model_id)\r\n",
    "    random_indices = np.random.choice(\r\n",
    "        dtrain.shape[0], size=round(dtrain.shape[0] * backgroud_portion), replace=False\r\n",
    "    )\r\n",
    "    backgroud_data = dtrain[random_indices, :]\r\n",
    "\r\n",
    "    if backgroud_portion == 1:\r\n",
    "        backgroud_data = dtrain\r\n",
    "\r\n",
    "    explainer = shap.TreeExplainer(\r\n",
    "        booster, feature_perturbation=\"interventional\", data=backgroud_data\r\n",
    "    )\r\n",
    "\r\n",
    "    train_shap_values = explainer.shap_values(dtrain)\r\n",
    "    np.savetxt(shap_train_fname, train_shap_values, delimiter=\",\")\r\n",
    "\r\n",
    "    test_shap_values = explainer.shap_values(dtest)\r\n",
    "    np.savetxt(shap_test_fname, test_shap_values, delimiter=\",\")\r\n",
    "\r\n",
    "    return 0\r\n",
    "\r\n",
    "\r\n",
    "eval_grid = np.genfromtxt(\r\n",
    "    \"./data/WS/model_fits/optimal_candidate_id.csv\",\r\n",
    "    delimiter=\",\",\r\n",
    "    skip_header=1,\r\n",
    "    dtype=\"int\",\r\n",
    ")\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "option, outer_i, model_id = eval_grid[0,:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "    shap_train_fname = (\r\n",
    "        \"./data/WS/model_fits/xgb_opt_\"\r\n",
    "        + option.__str__()\r\n",
    "        + \"_iter_\"\r\n",
    "        + outer_i.__str__()\r\n",
    "        + \"/shap_train_\"\r\n",
    "        + model_id.__str__()\r\n",
    "        + \".csv\"\r\n",
    "    )\r\n",
    "\r\n",
    "    shap_test_fname = (\r\n",
    "        \"./data/WS/model_fits/xgb_opt_\"\r\n",
    "        + option.__str__()\r\n",
    "        + \"_iter_\"\r\n",
    "        + outer_i.__str__()\r\n",
    "        + \"/shap_test_\"\r\n",
    "        + model_id.__str__()\r\n",
    "        + \".csv\"\r\n",
    "    )\r\n",
    "\r\n",
    "    # read dataset\r\n",
    "    dtrain, dtest = read_xgboost_data(option, outer_i, model_id)\r\n",
    "\r\n",
    "    # read model\r\n",
    "    booster = read_xgboost_model(option, outer_i, model_id)\r\n",
    "\r\n",
    "    # set up TreeExplainer\r\n",
    "    np.random.seed(option * outer_i * model_id)\r\n",
    "    random_indices = np.random.choice(\r\n",
    "        dtrain.shape[0], size=round(dtrain.shape[0] * 0.05), replace=False\r\n",
    "    )\r\n",
    "    backgroud_data = dtrain[random_indices, :]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "    explainer = shap.explainers.GPUTree(\r\n",
    "        booster, feature_perturbation=\"interventional\", data=backgroud_data\r\n",
    "    )\r\n",
    "\r\n",
    "    train_shap_values = explainer.shap_values(dtrain)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cuda extension was not built during install!\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "ImportError",
     "evalue": "cannot import name '_cext_gpu' from partially initialized module 'shap' (most likely due to a circular import) (C:\\Users\\User\\Anaconda3\\envs\\xgboost-env\\lib\\site-packages\\shap\\__init__.py)",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_16716/2179652295.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m )\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mtrain_shap_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshap_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\xgboost-env\\lib\\site-packages\\shap\\explainers\\_gpu_tree.py\u001b[0m in \u001b[0;36mshap_values\u001b[1;34m(self, X, y, tree_limit, approximate, check_additivity, from_call)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[1;31m# run the core algorithm using the C extension\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 105\u001b[1;33m         \u001b[0massert_import\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cext_gpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    106\u001b[0m         \u001b[0mphi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    107\u001b[0m         _cext_gpu.dense_tree_shap(\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\xgboost-env\\lib\\site-packages\\shap\\utils\\_general.py\u001b[0m in \u001b[0;36massert_import\u001b[1;34m(package_name)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimport_errors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpackage_name\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrecord_import_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpackage_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\xgboost-env\\lib\\site-packages\\shap\\explainers\\_gpu_tree.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0massert_import\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecord_import_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_cext_gpu\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mrecord_import_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cext_gpu\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"cuda extension was not built during install!\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_cext_gpu' from partially initialized module 'shap' (most likely due to a circular import) (C:\\Users\\User\\Anaconda3\\envs\\xgboost-env\\lib\\site-packages\\shap\\__init__.py)"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import shap\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import xgboost as xgb\r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "\r\n",
    "# Defining the dictionaries\r\n",
    "cpu_dict = {\r\n",
    "    'objective': 'reg:squarederror'\r\n",
    "}\r\n",
    "\r\n",
    "gpu_dict = {\r\n",
    "    'objective': 'reg:squarederror',\r\n",
    "    'tree_method': 'gpu_hist'\r\n",
    "}\r\n",
    "\r\n",
    "# Number of rows to train on \r\n",
    "nrows = [\r\n",
    "    10, \r\n",
    "    100, \r\n",
    "    200, \r\n",
    "    3000, \r\n",
    "    5000, \r\n",
    "    10000, \r\n",
    "    20000, \r\n",
    "    50000, \r\n",
    "    100000, \r\n",
    "    300000\r\n",
    "]\r\n",
    "cpu_speeds = []\r\n",
    "gpu_speeds = []\r\n",
    "\r\n",
    "for nrow in nrows: \r\n",
    "    # Sampling random rows \r\n",
    "    sample = pd.sample(nrow)\r\n",
    "    \r\n",
    "    # Creating X and Y \r\n",
    "    X = pd.get_dummies(sample[features])\r\n",
    "    Y = sample['Sales']\r\n",
    "    \r\n",
    "    # Initiating the model objects\r\n",
    "    cpu = xgb.XGBRegressor(**cpu_dict)\r\n",
    "    gpu = xgb.XGBRegressor(**gpu_dict)\r\n",
    "    \r\n",
    "    # Training on cpu \r\n",
    "    start = time.time()\r\n",
    "    cpu.fit(X, Y)\r\n",
    "    cpu_speed = time.time() - start\r\n",
    "    \r\n",
    "    # Training on gpu\r\n",
    "    start = time.time()\r\n",
    "    gpu.fit(X, Y)\r\n",
    "    gpu_speed = time.time() - start\r\n",
    "    \r\n",
    "    # Appending the speed results \r\n",
    "    cpu_speeds.append(cpu_speed)\r\n",
    "    gpu_speeds.append(gpu_speed)\r\n",
    "\r\n",
    "# Creating a dataframe \r\n",
    "speeds = pd.DataFrame({\r\n",
    "    'nrows': nrows,\r\n",
    "    'cpu_speeds': cpu_speeds,\r\n",
    "    'gpu_speeds': gpu_speeds\r\n",
    "})\r\n",
    "\r\n",
    "speeds['difference'] = speeds['cpu_speeds'] - speeds['gpu_speeds'] "
   ],
   "outputs": [
    {
     "output_type": "error",
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'sample'",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\Public\\Documents\\Wondershare\\CreatorTemp/ipykernel_16716/362712533.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnrow\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[1;31m# Sampling random rows\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0msample\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# Creating X and Y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\xgboost-env\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_SparseArray\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"module 'pandas' has no attribute '{name}'\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'sample'"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('xgboost-env': conda)"
  },
  "interpreter": {
   "hash": "24681ab95813adf834edbff34872209665896d23f7383384834c2fb87878d44d"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}